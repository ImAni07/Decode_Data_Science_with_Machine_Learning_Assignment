{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PWSkills Assignment\n",
    "Course: Decode Data Science With Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "1. Each Question Part consists of 3 Cells - (2 Markdown Cells, 1 each for question and the explanation or insights of the code & 1 Coding Cell with the Solution).\n",
    "2. Each Code has been Executed and the Output can be seen just below the Coding Cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question No. - 24:\n",
    "\n",
    "Calculate coefficient of correlation between the marks obtained by 10 students in Accountancy and Statistics:\n",
    "\n",
    "Student            1    2    3     4     5     6     7     8     9     10\n",
    "\n",
    "Accountancy        45   70   65    30    90    40    50    75    85    60 \n",
    "\n",
    "Statistics         35   90   70    40    95    40    60    80    80    50\n",
    "\n",
    "Use Karl Pearsonâ€™s Coefficient of Correlation Method to find it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student Marks DataFrame:\n",
      "                Accountancy  Statistics\n",
      "Student Number                         \n",
      "1                        45          35\n",
      "2                        70          90\n",
      "3                        65          70\n",
      "4                        30          40\n",
      "5                        90          95\n",
      "6                        40          40\n",
      "7                        50          60\n",
      "8                        75          80\n",
      "9                        85          80\n",
      "10                       60          50\n",
      "\n",
      "Mean of Accountancy marks = 61.0\n",
      "\n",
      "Mean of Statistics marks = 64.0\n",
      "\n",
      "Deviation from mean of Accountancy marks = Student Number\n",
      "1    -16.0\n",
      "2      9.0\n",
      "3      4.0\n",
      "4    -31.0\n",
      "5     29.0\n",
      "6    -21.0\n",
      "7    -11.0\n",
      "8     14.0\n",
      "9     24.0\n",
      "10    -1.0\n",
      "Name: Accountancy, dtype: float64\n",
      "\n",
      "Deviation from mean of Statistics marks = Student Number\n",
      "1    -29.0\n",
      "2     26.0\n",
      "3      6.0\n",
      "4    -24.0\n",
      "5     31.0\n",
      "6    -24.0\n",
      "7     -4.0\n",
      "8     16.0\n",
      "9     16.0\n",
      "10   -14.0\n",
      "Name: Statistics, dtype: float64\n",
      "\n",
      "The Coefficient of Correlation between the marks obtained by 10 students in Accountancy and Statistics = 0.9031178882610624\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Data for Accountancy and Statistics marks\n",
    "accountancy = np.array([45, 70, 65, 30, 90, 40, 50, 75, 85, 60])\n",
    "statistics = np.array([35, 90, 70, 40, 95, 40, 60, 80, 80, 50])\n",
    "\n",
    "# Create a DataFrame with Student Number as Index\n",
    "df = pd.DataFrame({'Accountancy': accountancy, 'Statistics': statistics}, index=range(1, len(accountancy) + 1))\n",
    "\n",
    "# Rename the Index to 'Student Number'\n",
    "df.index.name = 'Student Number'\n",
    "\n",
    "# Calculate the mean of Accountancy and Statistics marks\n",
    "mean_accountancy = df['Accountancy'].mean()\n",
    "mean_statistics = df['Statistics'].mean()\n",
    "\n",
    "# Calculate the deviation from mean for Accountancy and Statistics marks\n",
    "deviation_accountancy = df['Accountancy'] - mean_accountancy\n",
    "deviation_statistics = df['Statistics'] - mean_statistics\n",
    "\n",
    "# Calculate the correlation coefficient using pandas' function\n",
    "correlation_coefficient = df['Accountancy'].corr(df['Statistics'])\n",
    "\n",
    "# Print the DataFrame\n",
    "print(f\"Student Marks DataFrame:\\n{df}\")\n",
    "\n",
    "# Print the mean of Accountancy and Statistics marks\n",
    "print(f\"\\nMean of Accountancy marks = {mean_accountancy}\")\n",
    "print(f\"\\nMean of Statistics marks = {mean_statistics}\")\n",
    "\n",
    "# Print the deviation from mean for Accountancy and Statistics marks\n",
    "print(f\"\\nDeviation from mean of Accountancy marks = {deviation_accountancy}\")\n",
    "print(f\"\\nDeviation from mean of Statistics marks = {deviation_statistics}\")\n",
    "\n",
    "# Print the correlation coefficient\n",
    "print(f\"\\nThe Coefficient of Correlation between the marks obtained by 10 students in Accountancy and Statistics = {correlation_coefficient}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoding the Code:\n",
    "1. Importing the Required Library: The code starts by importing the NumPy and Pandas library. NumPy provides support for large, multi-dimensional arrays and matrices, along with a wide range of high-performance mathematical functions and Pandas is a popular library for data manipulation and analysis in Python.\n",
    "2. Defining the Data: The code defines two NumPy arrays, 'accountancy' and 'statistics', which contain the marks of students in Accountancy and Statistics, respectively, as already mentioned in the question. These arrays will be used to calculate the correlation coefficient.\n",
    "3. Creating a DataFrame: The code creates a pandas DataFrame 'df' using the 'pd.DataFrame' constructor. The DataFrame has two columns, 'Accountancy' and 'Statistics', which contain the marks of the students. The 'index' parameter is set to 'range(1, len(accountancy) + 1)', which creates a range of numbers from 1 to 10 (the number of students). This range is used as the index of the DataFrame, representing the student numbers.\n",
    "4. Renaming the Index: The code renames the index of the DataFrame to 'Student Number' using the 'index.name' attribute.\n",
    "5. Calculating the Mean: The code calculates the mean of each array using the 'np.mean()' function. The mean is a measure of central tendency that represents the average value of a dataset. Here, 'mean_accountancy' represents the mean of the Accountancy marks and 'mean_statistics' represents the mean of the Statistics marks.\n",
    "6. Calculating Deviations from the Mean: The code calculates the deviation of each mark from the mean by using <deviation_subject = subject_array - mean_subject>, which in this code for Accountancy, resembles to 'deviation_accountancy = accountancy - mean_accountancy' and for Statistics, it corresponds to 'deviation_statistics = statistics - mean_statistics;. These deviations will be used to calculate the correlation coefficient.\n",
    "7. Calculating the Correlation Coefficient: The code uses the 'np.corrcoef()' function to calculate the correlation coefficient between the Accountancy and Statistics marks. The 'corrcoef()' function returns a 2D array with the correlation coefficients, where the element at '[0, 1]' represents the correlation coefficient between the two arrays.\n",
    "8. Printing the Result: The code prints the calculated correlation coefficient, which is approximately '0.9031178882610624'. Also, the DataFrame created, the mean of both the subjects and deviation from mean for each marks in both the subjects have been printed.\n",
    "9. Insights and Interpretation: The correlation coefficient measures the strength and direction of the linear relationship between two variables. In this case, the correlation coefficient of '0.9031178882610624' indicates a strong positive linear relationship between the Accountancy and Statistics marks. This means that as the Accountancy marks increase, the Statistics marks also tend to increase, and vice versa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question No. - 26:\n",
    "\n",
    "Find the most likely price at Delhi corresponding to the price of Rs. 70 at Agra from the following data:\n",
    "\n",
    "Coefficient of correlation between the prices of the two places +0.8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most likely price at Delhi is: Rs. {56.0}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    According to the given question,\n",
    "    We only have,\n",
    "    Correlation Coefficient and \n",
    "    The Price at Agra.\n",
    "\"\"\"\n",
    "\n",
    "# The most likely price at Delhi, can be calculated using the correlation coefficient as follows:-\n",
    "\n",
    "# Given Values\n",
    "correlation_coefficient = 0.8\n",
    "price_at_agra = 70\n",
    "\n",
    "# The most likely price at Delhi\n",
    "price_at_delhi = correlation_coefficient * price_at_agra\n",
    "\n",
    "# Printing the Result\n",
    "print(f\"The most likely price at Delhi is: Rs.\", {price_at_delhi})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoding the Code:\n",
    "1. Objective: The code calculates the most likely price at Delhi using the correlation coefficient and the price at Agra.\n",
    "2. Assumption: Since, only the correlation coefficient and the price at Agra is available, a linear relationship is assumed to calculate the price at Delhi.\n",
    "3. Given Values: The values of correlation coefficient (r) = 0.8 and the price at Agra = 70, are given.\n",
    "4. Calculate the Most Likely Price at Delhi: The formula used here is 'price_at_delhi = correlation_coefficient * price_at_agra'. This is based on the assumption that the correlation coefficient represents the strength and direction of the linear relationship between the prices at Agra and Delhi.\n",
    "5. Print the Result: The calculated price at Delhi is printed to the console.\n",
    "6. Insights: The correlation coefficient (r) is a statistical measure that calculates the strength and direction of the linear relationship between two variables. In this case, it represents the relationship between the prices at Agra and Delhi. The correlation coefficient (r) is a statistical measure that calculates the strength and direction of the linear relationship between two variables. In this case, it represents the relationship between the prices at Agra and Delhi. The calculation 'price_at_delhi = correlation_coefficient * price_at_agra' assumes a linear relationship between the prices. In reality, the relationship may be more complex, and other factors may influence the prices. The output of the code is The most likely price at Delhi is: 'Rs. {56.0}', which indicates that the calculated price at Delhi is approximately Rs. 56.0.\n",
    "7. Code Review: The code is concise and easy to understand. However, it assumes a linear relationship between the prices, which may not always be the case in reality. Additionally, the code does not handle any potential errors or exceptions that may occur during the calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question No. - 27:\n",
    "\n",
    "In a partially destroyed laboratory record of an analysis of correlation data, the following results only are \n",
    "legible: \n",
    "\n",
    "Variance of x = 9, \n",
    "\n",
    "Regression equations are:\n",
    " \n",
    "(i) 8xâˆ’10y = âˆ’66;\n",
    "\n",
    "(ii) 40x âˆ’ 18y = 214.\n",
    "\n",
    "What are\n",
    "\n",
    "(a) the mean values of x and y, \n",
    "\n",
    "(b) the coefficient of correlation between x and y, \n",
    "\n",
    "(c) the Ïƒ of y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of x: -12.999999999999998\n",
      "\n",
      "Mean of y: 17.0\n",
      "\n",
      "Coefficient of Correlation = 0.6000000000000001\n",
      "\n",
      "Standard Deviation of y = 3.75\n"
     ]
    }
   ],
   "source": [
    "# Import Necessary Library\n",
    "import math\n",
    "\n",
    "# Given data\n",
    "var_x = 9\n",
    "\n",
    "# Standard deviation of x\n",
    "sigma_x = math.sqrt(9)\n",
    "\n",
    "# Regression equation coefficients\n",
    "\"\"\"\n",
    "    Equation 1: 8x - 10y = -66\n",
    "    Equation 2: 40x - 18y = 214\n",
    "\"\"\"\n",
    "a1, b1, c1 = 8, -10, -66 \n",
    "a2, b2, c2 = 40, -18, 214\n",
    "\n",
    "# Solving for the mean values of x and y\n",
    "# y = (a1/b1)x + c1/b1\n",
    "# y = (a2/b2)x + c2/b2\n",
    "# Equating the two y expressions at mean point\n",
    "mean_x = (c2/b2 - c1/b1) / ((a1/b1) - (a2/b2))\n",
    "mean_y = (a1/b1) * mean_x + c1/b1\n",
    "\n",
    "# Slopes of the regression lines\n",
    "b_yx = -(a1 / b1)\n",
    "b_xy = -(b2 / a2)\n",
    "\n",
    "# Coefficient of correlation r\n",
    "r = math.sqrt(b_yx * b_xy)\n",
    "\n",
    "# Standard deviation of y (sigma_y)\n",
    "sigma_y = sigma_x / b_yx\n",
    "\n",
    "# Output results\n",
    "print(f\"Mean of x: {mean_x}\\n\")\n",
    "print(f\"Mean of y: {mean_y}\\n\")\n",
    "print(f\"Coefficient of Correlation = {r}\\n\")\n",
    "print(f\"Standard Deviation of y = {sigma_y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoding the Code:\n",
    "1. Importing Necessary Library: The code starts by importing the 'math' library, which is used for mathematical operations such as square root calculations.\n",
    "2. Given Data: The code defines a variable 'var_x', which represents the variance of x, available as data in the question. Also two regression equations are available, whose coefficients are stored in variables a1, a2, b1, b2, c1 and c2.\n",
    "3. Standard Deviation of x: The code calculates the standard deviation of x using the formula 'sigma_x = sqrt(var_x)', where 'var_x' is the variance of x. In this case, 'var_x' is equal to 9, so 'sigma_x' is calculated as 'sqrt(9) = 3'.\n",
    "4. Mean Values of x and y: The code solves for the mean values of 'x' and 'y' by using the regression equations. The approach is to equate the two expressions for y at the mean point.\n",
    "5. Slopes of the Regression Lines: The code calculates the slopes of the regression lines.\n",
    "6. Coefficient of Correlation (r): The code calculates the coefficient of correlation 'r' using the formula: 'r = sqrt(b_yx * b_xy)'\n",
    "7. Standard Deviation of y: The code calculates the standard deviation of 'y' using the formula: 'sigma_y = sigma_x / b_yx'\n",
    "8. Output: Finally, the code prints the calculated values of 'mean_x', 'mean_y', 'r' and 'sigma_y'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question No. - 31:\n",
    "\n",
    "The mean of a distribution is 60 with a standard deviation of 10. Assuming that the distribution is normal, what percentage of items be \n",
    "\n",
    "(i) between 60 and 72, \n",
    "\n",
    "(ii) between 50 and 60, \n",
    "\n",
    "(iii) beyond 72 and \n",
    "\n",
    "(iv) between 70 and 80?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage between 60 and 72: 38.49%\n",
      "\n",
      "Percentage between 50 and 60: 34.13%\n",
      "\n",
      "Percentage beyond 72: 11.51%\n",
      "\n",
      "Percentage between 70 and 80: 13.59%\n"
     ]
    }
   ],
   "source": [
    "# Import Required Library\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Given Data\n",
    "mean_distribution = 60\n",
    "standard_deviation = 10\n",
    "\n",
    "# (i) Percentage of items between 60 and 72\n",
    "z1 = (60 - mean_distribution) / standard_deviation\n",
    "z2 = (72 - mean_distribution) / standard_deviation\n",
    "percentage_between_60_and_72 = stats.norm.cdf(z2) - stats.norm.cdf(z1)\n",
    "\n",
    "# (ii) Percentage of items between 50 and 60\n",
    "z1 = (50 - mean_distribution) / standard_deviation\n",
    "z2 = (60 - mean_distribution) / standard_deviation\n",
    "percentage_between_50_and_60 = stats.norm.cdf(z2) - stats.norm.cdf(z1)\n",
    "\n",
    "# (iii) Percentage of items beyond 72\n",
    "z = (72 - mean_distribution) / standard_deviation\n",
    "percentage_beyond_72 = 1 - stats.norm.cdf(z)\n",
    "\n",
    "# (iv) Percentage of items between 70 and 80\n",
    "z1 = (70 - mean_distribution) / standard_deviation\n",
    "z2 = (80 - mean_distribution) / standard_deviation\n",
    "percentage_between_70_and_80 = stats.norm.cdf(z2) - stats.norm.cdf(z1)\n",
    "\n",
    "# Printing the Results\n",
    "\n",
    "# For (i):\n",
    "print(f\"Percentage between 60 and 72: {percentage_between_60_and_72 * 100:.2f}%\")\n",
    "\n",
    "# For (ii):\n",
    "print(f\"\\nPercentage between 50 and 60: {percentage_between_50_and_60 * 100:.2f}%\")\n",
    "\n",
    "# For (iii):\n",
    "print(f\"\\nPercentage beyond 72: {percentage_beyond_72 * 100:.2f}%\")\n",
    "\n",
    "# For (iv):\n",
    "print(f\"\\nPercentage between 70 and 80: {percentage_between_70_and_80 * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoding the code:\n",
    "1. Import the required Library: Here, 'scipy.stats' is imported, which provides functions for statistical calculations, including working with normal distributions.\n",
    "2. Defining the Given Data: The code defines the mean ('mean_distribution') and standard deviation ('standard_deviation') of a normal distribution. In this case, the mean is 60 and the standard deviation is 10.\n",
    "3. Calculating the Z-Score: The code calculates the z-scores for each of the given intervals. A z-score is a measure of how many standard deviations an observation is away from the mean.\n",
    "4. Calculating the Cumulative Distribution Function (CDF): The code uses the 'stats.norm.cdf()' function to calculate the cumulative distribution function (CDF) of the standard normal distribution at the calculated z-scores.\n",
    "5. Calculating the Percentages: The code multiplies the calculated probabilities by 100 to convert them to percentages.\n",
    "6. Insights: The normal distribution is symmetric around the mean, so the percentage of items between 50 and 60 is similar to the percentage of items between 60 and 70 (not calculated in this code). The percentage of items beyond 72 is relatively low, indicating that most items in the distribution fall below 72. The percentage of items between 70 and 80 is higher than the percentage of items beyond 72, indicating that there is a higher concentration of items in this range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question No. - 32:\n",
    "\n",
    "15000 students sat for an examination. The mean marks was 49 and the distribution of marks had a standard deviation of 6.\n",
    "Assuming that the marks were normally distributed what proportion of students scored \n",
    "\n",
    "(a) more than 55 marks, \n",
    "\n",
    "(b) more than 70 marks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of students scoring more than 55 marks: 15.87%\n",
      "Number of students scoring more than 55 marks: 2380\n",
      "\n",
      "Proportion of students scoring more than 70 marks: 0.02%\n",
      "Number of students scoring more than 70 marks: 3\n"
     ]
    }
   ],
   "source": [
    "# Import Required Library\n",
    "import scipy.stats as stats\n",
    "\n",
    "mean_marks = 49\n",
    "standard_deviation_marks = 6\n",
    "total_students = 15000\n",
    "\n",
    "# (a) Proportion of students who scored more than 55 marks\n",
    "z = (55 - mean_marks) / standard_deviation_marks\n",
    "proportion_more_than_55 = 1 - stats.norm.cdf(z)\n",
    "students_more_than_55 = proportion_more_than_55 * total_students\n",
    "\n",
    "# (b) Proportion of students who scored more than 70 marks\n",
    "z = (70 - mean_marks) / standard_deviation_marks\n",
    "proportion_more_than_70 = 1 - stats.norm.cdf(z)\n",
    "students_more_than_70 = proportion_more_than_70 * total_students\n",
    "\n",
    "# Printing the Results\n",
    "\n",
    "# For (a):\n",
    "print(f\"Proportion of students scoring more than 55 marks: {proportion_more_than_55 * 100:.2f}%\")\n",
    "print(f\"Number of students scoring more than 55 marks: {students_more_than_55:.0f}\")\n",
    "\n",
    "# For (b):\n",
    "print(f\"\\nProportion of students scoring more than 70 marks: {proportion_more_than_70 * 100:.2f}%\")\n",
    "print(f\"Number of students scoring more than 70 marks: {students_more_than_70:.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoding the Code:\n",
    "1. Import Required Library: In this case, 'scipy.stats' is imported.\n",
    "2. Given Data: Defining the data available in the question. In this case, they are the total number of students (total_students), mean marks (mean_marks) and standard deviation (stamdard_deviation_marks).\n",
    "3. Calculating the Proportion of Students: The z-score is calculated as z = (X - Î¼) / Ïƒ.\n",
    "4. Printing the Results: The code prints the proportion of students as well as the number of students obtaining more than 55 marks and more than 70 marks.\n",
    "5. Insights: The output shows that about 15.87% of students scored more than 55 marks, which translates to approximately 2,380 students and only about 0.02% of students scored more than 70 marks, which translates to approximately 3 students. These results suggest that the scores are normally distributed, with the majority of students scoring around the mean (49). The proportion of students who scored more than 55 marks is relatively high, indicating that the scores are somewhat skewed to the right. The extremely low proportion of students who scored more than 70 marks suggests that the scores are tightly clustered around the mean, with very few outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question No. 33:\n",
    "\n",
    "If the height of 500 students are normally distributed with mean 65 inch and standard deviation 5 inch.\n",
    "How many students have height: \n",
    "\n",
    "(a) greater than 70 inch.\n",
    "\n",
    "(b) between 60 and 70 inch? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of students with height greater than 70 inches: 79\n",
      "Number of students with height between 60 and 70 inches: 341\n"
     ]
    }
   ],
   "source": [
    "# Import Required Library\n",
    "import scipy.stats as stats\n",
    "\n",
    "mean_height = 65\n",
    "standard_deviation_height = 5\n",
    "number_of_students = 500\n",
    "\n",
    "# (a) Number of students with height greater than 70 inches\n",
    "z = (70 - mean_height) / standard_deviation_height\n",
    "proportion_greater_than_70 = 1 - stats.norm.cdf(z)\n",
    "students_greater_than_70 = proportion_greater_than_70 * number_of_students\n",
    "\n",
    "# (b) Number of students with height between 60 and 70 inches\n",
    "z1 = (60 - mean_height) / standard_deviation_height\n",
    "z2 = (70 - mean_height) / standard_deviation_height\n",
    "proportion_between_60_and_70 = stats.norm.cdf(z2) - stats.norm.cdf(z1)\n",
    "students_between_60_and_70 = proportion_between_60_and_70 * number_of_students\n",
    "\n",
    "# Printing the Results\n",
    "\n",
    "# For (a):\n",
    "print(f\"Number of students with height greater than 70 inches: {students_greater_than_70:.0f}\")\n",
    "\n",
    "# For (b):\n",
    "print(f\"Number of students with height between 60 and 70 inches: {students_between_60_and_70:.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoding the Code:\n",
    "1. Import Required Library: In this case, 'scipy.stats' is imported.\n",
    "2. Given Data: Defining the data available in the question. In this case, they are the total number of students (number_of_students), mean height (mean_height) and standard deviation (stamdard_deviation_height).\n",
    "3. Calculating the Proportion of Students: The z-score is calculated and the required proportion is calculated.\n",
    "4. Printing the Results: The code prints the results of the calculations, rounding the numbers to the nearest integer using the ':.0f' format specifier.\n",
    "5. Insights: The output of the code suggests that approximately 79 students (out of 500) have a height greater than 70 inches. This is a reasonable number, considering that the mean height is 65 inches and the standard deviation is 5 inches and approximately 341 students (out of 500) have a height between 60 and 70 inches. This is a large proportion of the total number of students, indicating that the heights are concentrated around the mean. The results seem reasonable and consistent with the parameters defined in the code. The code correctly uses the 'stats.norm.cdf()' function to calculate the proportions of students with heights in different ranges, and the results are consistent with the expected values for a normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question No. - 35:\n",
    "\n",
    "A random sample of size 25 from a population gives the sample standard derivation to be 9.0.\n",
    "Test the hypothesis that the population standard derivation is 10.5.\n",
    "\n",
    "Hint (Use chi-square distribution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-square statistic: 17.63\n",
      "Critical values: (12.40, 39.36)\n",
      "Fail to reject the null hypothesis: There is not enough evidence to say the population standard deviation is different from 10.5.\n"
     ]
    }
   ],
   "source": [
    "# Import Necessary Library\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Given Data\n",
    "n = 25\n",
    "sample_std = 9.0\n",
    "population_std = 10.5\n",
    "\n",
    "# Assuming the value of alpha\n",
    "alpha = 0.05\n",
    "\n",
    "# Calculate the chi-square statistic\n",
    "chi_square_stat = (n - 1) * (sample_std ** 2) / (population_std ** 2)\n",
    "\n",
    "# Degrees of freedom\n",
    "df = n - 1\n",
    "\n",
    "# Calculate the critical values for a two-tailed test\n",
    "chi_square_critical_low = stats.chi2.ppf(alpha / 2, df)\n",
    "chi_square_critical_high = stats.chi2.ppf(1 - alpha / 2, df)\n",
    "\n",
    "print(f\"Chi-square statistic: {chi_square_stat:.2f}\")\n",
    "print(f\"Critical values: ({chi_square_critical_low:.2f}, {chi_square_critical_high:.2f})\")\n",
    "\n",
    "# Decision rule\n",
    "if chi_square_stat < chi_square_critical_low or chi_square_stat > chi_square_critical_high:\n",
    "    print(\"Reject the null hypothesis: The population standard deviation is not 10.5.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: There is not enough evidence to say the population standard deviation is different from 10.5.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoding the Code:\n",
    "1. Import Required Library: In this case, 'scipy.stats' is imported.\n",
    "2. Given Data: The code defines the data available in the question - sample size as 'n', the sample standard deviation as 'sample_std' and the population standard deviation as 'population_std'.\n",
    "3. The value of alpha has been assumed to be 0.5\n",
    "4. Calculation of chi-square statistic: The code calculates the chi-square statistic using the formula: 'chi_square_stat = (n - 1) * (sample_std ** 2) / (population_std ** 2)'. This formula is used to calculate the chi-square statistic for a test of the population standard deviation.\n",
    "5. Degrees of Freeedom: The code calculates the degrees of freedom ('df') as 'n - 1', which is 24 in this case.\n",
    "6. Calculation of Critical Values: The code calculates the critical values for a two-tailed test using the ppf function from 'scipy.stats'. The 'ppf' function returns the critical value for a given probability and degrees of freedom.\n",
    "7. Print Results: The code prints the calculated chi-square statistic and the critical values and also applies the decision rule as if the calculated chi-square statistic is less than the critical value for the lower tail (chi_square_critical_low) or greater than the critical value for the upper tail (chi_square_critical_high), the null hypothesis is rejected, otherwise the null hypothesis is not rejected.\n",
    "8. Insights: In this case, the calculated chi-square statistic (17.63) is between the critical values (12.40 and 39.36), so the null hypothesis is not rejected. The output message indicates that there is not enough evidence to say the population standard deviation is different from 10.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question No. - 37:\n",
    "\n",
    "100 students of a PW IOI obtained the following grades in Data Science paper:\n",
    "\n",
    "Grade:           [A,  B,  C,   D,  E]\n",
    "\n",
    "Total Frequency: [15, 17, 30, 22, 16, 100]\n",
    "\n",
    "Using the  Ï‡ 2 test , examine the hypothesis that the distribution of grades is uniform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grade Frequencies:\n",
      "  Grade  Frequency\n",
      "0     A         15\n",
      "1     B         17\n",
      "2     C         30\n",
      "3     D         22\n",
      "4     E         16\n",
      "\n",
      "Chi-square statistic: 7.70\n",
      "P-value: 0.1032\n",
      "\n",
      "Fail to reject the null hypothesis: The distribution of grades is uniform.\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "# Define grades and their frequencies\n",
    "grades = ['A', 'B', 'C', 'D', 'E']\n",
    "frequencies = [15, 17, 30, 22, 16]\n",
    "\n",
    "# Create a DataFrame to store grades and frequencies\n",
    "df = pd.DataFrame({'Grade': grades, 'Frequency': frequencies})\n",
    "\n",
    "# Print the DataFrame\n",
    "print(f\"Grade Frequencies:\\n{df}\")\n",
    "\n",
    "# Calculate total observations\n",
    "total_observations = np.sum(frequencies)\n",
    "\n",
    "# Calculate expected frequencies\n",
    "expected_frequencies = np.full_like(frequencies, total_observations / len(frequencies))\n",
    "\n",
    "# Perform chi-square test\n",
    "chi_square_stat, p_value = stats.chisquare(frequencies, f_exp=expected_frequencies)\n",
    "\n",
    "# Print the Output of Chi-Square Statistic and p-value\n",
    "print(f\"\\nChi-square statistic: {chi_square_stat:.2f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "\n",
    "# Decision rule at alpha = 0.05\n",
    "alpha = 0.05\n",
    "\n",
    "# Check the Condition and print the decision to either reject or fail to reject the Null Hypothesis\n",
    "if p_value < alpha:\n",
    "    print(\"\\nReject the null hypothesis: The distribution of grades is not uniform.\")\n",
    "else:\n",
    "    print(\"\\nFail to reject the null hypothesis: The distribution of grades is uniform.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoding the Code:\n",
    "1. Import Libraries: The code starts with importing all the necessary libraries. In this case, these are 'numpy', 'pandas' and 'scipy.stats'.\n",
    "2. Defining the Available Data: The code defines the Grade and Frequencies as 2 separate lists, 'grades' and 'frequencies', respectively.\n",
    "3. Creation of DataFrame: The code creates a Pandas DataFrame 'df' with two columns: 'Grade' and 'Frequency'. The 'Grade' column contains the grade labels, and the 'Frequency' column contains the corresponding frequencies.\n",
    "4. Printing the DataFrame: The code prints the DataFrame to the console, showing the grade frequencies.\n",
    "5. Calculating Observations: The code calculates the total number of observations by summing up the frequencies using 'np.sum(frequencies)' and the code calculates the expected frequencies under the null hypothesis of a uniform distribution. Since there are 5 grades, the expected frequency for each grade is the total number of observations divided by 5, which is calculated using 'np.full_like(frequencies, total_observations / len(frequencies))'.\n",
    "6. Perform Chi-Square Test: The code performs a chi-square test using 'stats.chisquare(frequencies, f_exp=expected_frequencies)' to determine whether the observed frequencies are significantly different from the expected frequencies under the null hypothesis. The test returns two values: the chi-square statistic and the p-value.\n",
    "7. Printing the Result of Chi-Square Test and P-Value: The code prints the chi-square statistic and p-value to the console.\n",
    "8. Decision Rule: The code sets an alpha level of 0.05, which means that if the p-value is less than 0.05, the null hypothesis will be rejected.\n",
    "9. Checking Condition and Printing the Decision: The code checks whether the p-value is less than the alpha level. If it is, the code prints \"Reject the null hypothesis: The distribution of grades is not uniform.\" Otherwise, it prints \"Fail to reject the null hypothesis: The distribution of grades is uniform.\"\n",
    "10. Insights: Based on the output, it can be concluded that the chi-square statistic is 7.70, which indicates that there is some deviation from the expected frequencies under the null hypothesis; the p-value is 0.1032, which is greater than the alpha level of 0.05. This means that we fail to reject the null hypothesis. Therefore, we conclude that the distribution of grades is uniform, meaning that the observed frequencies are not significantly different from the expected frequencies under the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question No. - 38:\n",
    "\n",
    "Perform ANOVA Test:\n",
    "\n",
    "To study the performance of three detergents and three different water temperatures, the following whiteness readings were obtained with specially designed equipment:\n",
    "\n",
    "Water Temperature      Detergent A      Detergent B      Detergent C\n",
    "\n",
    "Cold Water                57                 55                67\n",
    "\n",
    "Warm Water                49                 52                68\n",
    "\n",
    "Hot Water                 54                 46                58"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame:\n",
      "             Cold Water  Warm Water  Hot Water\n",
      "Detergent A          57          49         54\n",
      "Detergent B          55          52         46\n",
      "Detergent C          67          68         58\n",
      "\n",
      "F-Value: 0.6029\n",
      "P-Value: 0.5773\n",
      "\n",
      "Since p-value >= 0.05, we fail to reject the null hypothesis. There is no significant difference in means.\n"
     ]
    }
   ],
   "source": [
    "# Import Necessary Libraries\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Data for the ANOVA test\n",
    "data = {\n",
    "    'Cold Water': [57, 55, 67],\n",
    "    'Warm Water': [49, 52, 68],\n",
    "    'Hot Water': [54, 46, 58]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data, index=['Detergent A', 'Detergent B', 'Detergent C'])\n",
    "\n",
    "# Display the DataFrame\n",
    "print(f\"DataFrame:\\n{df}\")\n",
    "\n",
    "# Perform ANOVA\n",
    "f_val, p_val = stats.f_oneway(df['Cold Water'], df['Warm Water'], df['Hot Water'])\n",
    "\n",
    "# Display the F-value and p-value\n",
    "print(f\"\\nF-Value: {f_val:.4f}\")\n",
    "print(f\"P-Value: {p_val:.4f}\")\n",
    "\n",
    "# Conclusion based on p-value\n",
    "alpha = 0.05\n",
    "if p_val < alpha:\n",
    "    print(\"\\nSince p-value < 0.05, we reject the null hypothesis. There is a significant difference in means.\")\n",
    "else:\n",
    "    print(\"\\nSince p-value >= 0.05, we fail to reject the null hypothesis. There is no significant difference in means.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoding the Code:\n",
    "1. Import Necessary Libraries: The code start by importing two ibraries - 'pandas' and 'scipy.stats'.\n",
    "2. Defining Data: The code defines a dictionary 'data' containing three lists of values, each representing a different water temperature condition, namely Cold Water, Warm Water and Hot Water, as it is available in the question.\n",
    "3. Creation of DataFrame: The code creates a Pandas DataFrame 'df' from the 'data' dictionary, using the 'pd.DataFrame()' function. The index parameter is set to '['Detergent A', 'Detergent B', 'Detergent C']', which means that each row of the DataFrame will be labeled with one of these detergent names.\n",
    "4. Performing ANOVA: The code performs a one-way ANOVA (Analysis of Variance) test using the 'stats.f_oneway()' function from SciPy. This function takes three arguments: the three lists of values from the DataFrame, corresponding to the three water temperature conditions. The ANOVA test is used to determine whether there are significant differences between the means of the three groups (Cold Water, Warm Water, and Hot Water).\n",
    "5. Displaying Results: The code displays the results of the ANOVA Test, in terms of F-Value and P-Value.\n",
    "6. Conclusion: The code uses the P-Value to determine whether to reject or fail to reject the null hypothesis. The null hypothesis is that there is no significant difference between the means of the three groups. If the P-Value is less than a certain significance level (usually 0.05), the null hypothesis is rejected, indicating that there is a significant difference between the means. Otherwise, the null hypothesis is not rejected, indicating that there is no significant difference. In this case, the P-Value (0.5773) is greater than the significance level (0.05), so the code concludes that there is no significant difference between the means of the three groups."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
